\documentclass[12pt, titlepage]{article}

\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=blue,
    filecolor=black,
    linkcolor=red,
    urlcolor=blue
}
\usepackage[round]{natbib}
\usepackage{caption}
\usepackage[letterpaper, portrait, margin=1in]{geometry}
\usepackage{helvet}
\usepackage{hyphenat}

\input{../Comments}
\input{../Common}

\begin{document}

\title{Project Title: System Verification and Validation Plan for \progname{}}
\author{\authname}
\date{\today}

\maketitle

\pagenumbering{roman}

\section{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
  \toprule {\bf Date} & {\bf Version} & {\bf Notes} \\
  \midrule
  Date 1              & 1.0           & Notes       \\
  Date 2              & 1.1           & Notes       \\
  \bottomrule
\end{tabularx}

\newpage

\tableofcontents

\listoftables
\wss{Remove this section if it isn't needed}

\listoffigures
\wss{Remove this section if it isn't needed}

\newpage

\section{Symbols, Abbreviations and Acronyms}

\renewcommand{\arraystretch}{1.2}
\begin{tabular}{l l}
  \toprule
  \textbf{symbol} & \textbf{description} \\
  \midrule
  T               & Test                 \\
  \bottomrule
\end{tabular}\\

\wss{symbols, abbreviations or acronyms --- you can simply reference the SRS
  \citep{SRS} tables, if appropriate}

\wss{Remove this section if it isn't needed}

\newpage

\pagenumbering{arabic}

This document ... \wss{provide an introductory blurb and roadmap of the
  Verification and Validation plan}

\section{General Information}

\subsection{Summary}

\wss{Say what software is being tested.  Give its name and a brief overview of
  its general functions.}

\subsection{Objectives}

\wss{State what is intended to be accomplished.  The objective will be around
  the qualities that are most important for your project.  You might have
  something like: ``build confidence in the software correctness,''
  ``demonstrate adequate usability.'' etc.  You won't list all of the qualities,
  just those that are most important.}

\subsection{Relevant Documentation}

\wss{Reference relevant documentation.  This will definitely include your SRS
  and your other project documents (design documents, like MG, MIS, etc).  You
  can include these even before they are written, since by the time the project
  is done, they will be written.}

\citet{SRS}

\section{Plan}

Verification and Validation plan will be done on both the hardware and software side individually as well as the system integration. The Researcher/Stakeholders and Back End developers will have different roles and techniques to test the device's functionality and usability as described below.

\subsection{Verification and Validation Team}

The following table defines the roles for the stakeholder and Back End Developers team for Verification and Validation.
\begin{center}
\begin{tabular}{|m{5em}|m{5em}|m{25em}|}

  \hline
  \textbf{Name}     & \textbf{Role}           & \textbf{Description}                                                                                                                                                                        \\
  \hline
  Dr Luciano Macedo & End user                & Stakeholder who will be the end user, verifying all the user requirements and functionality in every sprints.                                                                                                             \\
  \hline
  Johnathan Hai     & Subsystem tester       & There will be a set of test cases pre-defined for every functional requirement. Jonathan will be testing the specific functions against the test cases using unit testing, integration testing and boundary condition tests as well as SRS verification. \\
  \hline
  Jessica Bae       & Black Box tester        & Testing the specific functions without knowing how the internal workflow is structured. This will include stress testing for I/O for all subsytems and boundary condition testing. Valgrind will also be used for code profiling and debugging memory leaks.                                                                                         \\
  \hline
  Labeeb Zaker      & Remote codebase manager & Ensuring the codebase on GitHub has no flaws, maintaining CI/CD, reviewing every commit added to ensure it meets the requirements without any possible case of errors. \\
  \hline
  Nish Shah         & Automated tester        & Maintaining the automated testing scripts to run certain functions against test cases that are repetitive to keep checking code is functional. Primarily using Python code coverage tools and unit testing frameworks for code development (unittest, Coverage.py).                                                          \\
  \hline
  Anish Rangarajan  & Hardware \& Automated tester    & Verification and testing of embedded development/hardware in C using Cunit and bullseye coverage for unit testing framework and code coverage.\\
  \hline
  Oliver Foote      & White Box \& Database testing        & Testing the internal workflow such that for a given set of inputs, an expected output is returned. Database validation using Orion for stress test of I/O and database functionality. \\
  \hline

\end{tabular}
  \captionof{table}{Team roles for Verification and Validation.}
  \end{center}

\subsection{SRS Verification Plan}\label{SRS_verification}

The SRS verification plan will follow a checklist for reviewers based on an ad hoc approach. It will also follow a rigorous task based inspection listed in the table below. This is to make sure all the requirements and goals receive several iterations of verification and validation.


\begin{center}
\begin{tabular}{|m{3cm}|m{8cm}|m{4cm}|} 

  \hline
  \textbf{Section of SRS}     & \textbf{Description}           & \textbf{Approach of Feedback}                                                                                                                                                                       
  \\
  \hline
  General feedback and discussion & The verification will be done based on an ad hoc approach through the checklist below: \begin{itemize}
  \item Verify System constrains for hardware and software.
  \item Monitored and controlled variables are consistent.
  \item Comparison to existing solutions is unambiguous.
  \item Project Goals are relevant to description of device.
  \item Requirements (functional \& non-functional) are prioritized and verified.
  \item Event handling and FSM is verified and correct.
  \end{itemize}               & Will be done by Stakeholder Dr Luciana Macedo, supervisor, classmates and Back-end Developers.\\
  \hline
  General System Description 4.1-4.3  & The verification for this section would be checking if System constrains and user characteristics are provided in detail without any ambiguity.                & Will be done by team member Jonathan Hai.                                                                                                             \\
  \hline
  Section 5 Definitions and variables     & Verifying if terminology and the use of monitored and controlled variables is consistent and correct. Assumptions are clearly mentioned and provided along with goals of the project.        & Will be done by team member  Nish Shah.\\
  \hline
  Required behavior and Requirements       & Validation of Functional and Non-functional requirements and to verify if the requirements are classified correctly. Checking required behavior as well.       & Will be done by team member Anish Rangarajan.                                                                                         \\
  \hline
  Section 8-12 Traceability matrices and normal operation      & Verification of matrices and graphs according to Requirements and also verifying if normal operation covers the required goals of the device. & Will be done by team member Labeeb Zaker.\\
  \hline
  Section 14-16        & Verification of FSM, Legal factors and Phase in Plan.       & Will be done by team member Jessica bae.                                                          \\
  \hline
\end{tabular}
  \end{center}
\captionof{table}{SRS verification checklist and task based inspection}
\subsection{Design Verification Plan}

\wss{Plans for design verification}

\wss{The review will include reviews by your classmates}

\wss{Create a checklists?}

\subsection{Verification and Validation Plan Verification Plan}

\wss{The verification and validation plan is an artifact that should also be verified.}

\wss{The review will include reviews by your classmates}

\wss{Create a checklists?}

\subsection{Implementation Verification Plan}

The Implementation Verification Plan will involve static and dynamic code analysis as the debugging methods to find bugs early in development. The checklist below can be used in development to follow the Implementation verification plan.\\
The following methods will be used for static code analysis:
\begin{itemize}
\item Bi-weekly code review with sub-teams (hardware, software, frontend/backend) for code walk through.
\item Weekly code review with entire team for system-level software design.
\item Use a SAST tool to scan source code, binary and byte code to reveal vulnerabilities.
\item Use static analysis tools such as Pylint, lint described in \ref{Automation} to find bugs in code.
\end{itemize}
Dynamic code testing will help identify exploitable vulnerabilities. The following methods will be used for dynamic code analysis:
\begin{itemize}
\item Use a DAST tool as a black-box tester which inputs malicious SQL queries, Long input strings and invalid data to exploit assumptions made by developers.
\item Running modular code separately against variety of inputs to find bugs in code.
\item Use open source tools based on the programming language (CrossHair for Python, CHAP for C) to provide a comprehensive view of performance and security of the device.
\end{itemize}


\subsection{Automated Testing and Verification Tools}\label{Automation}

Automated testing and verification tools will be based on the different programming languages and tools used in the development of the device. As covered in the development plan, (reference dev plan>>>) the following unit testing frameworks, profiling tools and linters will be used for verification of code:

\begin{itemize}
\item Python: 
	\begin{itemize}
		 \item unittest will be used as the Unit testing framework for Python to cover test automation, aggregation of tests (integration 							testing) and independence of tests from the reporting framework.
		\item Coverage.py will be used to measure code coverage and to gauge the effectiveness of tests performed.
		\item Pylint will be used as the linter/static code analyser which will check for errors and enforce a coding standard.
	\end{itemize}
\item C: 
	\begin{itemize}
	\item CUnit will be used as a unit testing framework for embedded system development.
	\item Bullseye coverage will be used for C code coverage analysis.
	\item lint will be used as the linter/static code analyser for development in C.
	\end{itemize}
\item Valgrind will be used for Python (pytest-valgrind) and C as a debugging tool for code profiling.
\item SQL/Database testing: Orion will be used to stress test an I/O coverage and to make sure the database functions as expected.
\end{itemize}

\subsection{Software Validation Plan}

There will be no plan for Software validation since there is no external data used and all the software-related validation is covered in  section \ref{SRS_verification}.

\section{System Test Description}

\subsection{Tests for Functional Requirements}

\wss{Subsets of the tests may be in related, so this section is divided into
  different areas.  If there are no identifiable subsets for the tests, this
  level of document structure can be removed.}

\wss{Include a blurb here to explain why the subsections below
  cover the requirements.  References to the SRS would be good here.}

\subsubsection{Area of Testing1}

\wss{It would be nice to have a blurb here to explain why the subsections below
  cover the requirements.  References to the SRS would be good here.  If a section
  covers tests for input constraints, you should reference the data constraints
  table in the SRS.}

\paragraph{Title for Test}

\begin{enumerate}

  \item{test-id1\\}

  Control: Manual versus Automatic

  Initial State:

  Input:

  Output: \wss{The expected result for the given inputs}

  Test Case Derivation: \wss{Justify the expected value given in the Output field}

  How test will be performed:

  \item{test-id2\\}

  Control: Manual versus Automatic

  Initial State:

  Input:

  Output: \wss{The expected result for the given inputs}

  Test Case Derivation: \wss{Justify the expected value given in the Output field}

  How test will be performed:

\end{enumerate}

\subsubsection{Area of Testing2}

...

\subsection{Tests for Nonfunctional Requirements}

\wss{The nonfunctional requirements for accuracy will likely just reference the
  appropriate functional tests from above.  The test cases should mention
  reporting the relative error for these tests.  Not all projects will
  necessarily have nonfunctional requirements related to accuracy}

\wss{Tests related to usability could include conducting a usability test and
  survey.  The survey will be in the Appendix.}

\wss{Static tests, review, inspections, and walkthroughs, will not follow the
  format for the tests given below.}

\subsubsection{Area of Testing1}

\paragraph{Title for Test}

\begin{enumerate}

  \item{test-id1\\}

  Type: Functional, Dynamic, Manual, Static etc.

  Initial State:

  Input/Condition:

  Output/Result:

  How test will be performed:

  \item{test-id2\\}

  Type: Functional, Dynamic, Manual, Static etc.

  Initial State:

  Input:

  Output:

  How test will be performed:

\end{enumerate}

\subsubsection{Area of Testing2}

...

\subsection{Traceability Between Test Cases and Requirements}

\wss{Provide a table that shows which test cases are supporting which
  requirements.}

\section{Unit Test Description}

\wss{Reference your MIS (detailed design document) and explain your overall
  philosophy for test case selection.}
\wss{This section should not be filled in until after the MIS (detailed design
  document) has been completed.}

\subsection{Unit Testing Scope}

\wss{What modules are outside of the scope.  If there are modules that are
  developed by someone else, then you would say here if you aren't planning on
  verifying them.  There may also be modules that are part of your software, but
  have a lower priority for verification than others.  If this is the case,
  explain your rationale for the ranking of module importance.}

\subsection{Tests for Functional Requirements}

\wss{Most of the verification will be through automated unit testing.  If
  appropriate specific modules can be verified by a non-testing based
  technique.  That can also be documented in this section.}

\subsubsection{Module 1}

\wss{Include a blurb here to explain why the subsections below cover the module.
  References to the MIS would be good.  You will want tests from a black box
  perspective and from a white box perspective.  Explain to the reader how the
  tests were selected.}

\begin{enumerate}

  \item{test-id1\\}

  Type: \wss{Functional, Dynamic, Manual, Automatic, Static etc. Most will
    be automatic}

  Initial State:

  Input:

  Output: \wss{The expected result for the given inputs}

  Test Case Derivation: \wss{Justify the expected value given in the Output field}

  How test will be performed:

  \item{test-id2\\}

  Type: \wss{Functional, Dynamic, Manual, Automatic, Static etc. Most will
    be automatic}

  Initial State:

  Input:

  Output: \wss{The expected result for the given inputs}

  Test Case Derivation: \wss{Justify the expected value given in the Output field}

  How test will be performed:

  \item{...\\}

\end{enumerate}

\subsubsection{Module 2}

...

\subsection{Tests for Nonfunctional Requirements}

\wss{If there is a module that needs to be independently assessed for
  performance, those test cases can go here.  In some projects, planning for
  nonfunctional tests of units will not be that relevant.}

\wss{These tests may involve collecting performance data from previously
  mentioned functional tests.}

\subsubsection{Module ?}

\begin{enumerate}

  \item{test-id1\\}

  Type: \wss{Functional, Dynamic, Manual, Automatic, Static etc. Most will
    be automatic}

  Initial State:

  Input/Condition:

  Output/Result:

  How test will be performed:

  \item{test-id2\\}

  Type: Functional, Dynamic, Manual, Static etc.

  Initial State:

  Input:

  Output:

  How test will be performed:

\end{enumerate}

\subsubsection{Module ?}

...

\subsection{Traceability Between Test Cases and Modules}

\wss{Provide evidence that all of the modules have been considered.}

\bibliographystyle{plainnat}

\bibliography{../../refs/References}

\newpage

\section{Appendix}

This is where you can place additional information.

\subsection{Symbolic Parameters}

The definition of the test cases will call for SYMBOLIC\_CONSTANTS.
Their values are defined in this section for easy maintenance.

\subsection{Usability Survey Questions?}

\wss{This is a section that would be appropriate for some projects.}

\newpage{}
\section*{Appendix --- Reflection}

The information in this section will be used to evaluate the team members on the
graduate attribute of Lifelong Learning.  Please answer the following questions:

\newpage{}
\section*{Appendix --- Reflection}

The information in this section will be used to evaluate the team members on the
graduate attribute of Lifelong Learning.  Please answer the following questions:

\begin{enumerate}
  \item What knowledge and skills will the team collectively need to acquire to
        successfully complete the verification and validation of your project?
        Examples of possible knowledge and skills include dynamic testing knowledge,
        static testing knowledge, specific tool usage etc.  You should look to
        identify at least one item for each team member.
  \item For each of the knowledge areas and skills identified in the previous
        question, what are at least two approaches to acquiring the knowledge or
        mastering the skill?  Of the identified approaches, which will each team
        member pursue, and why did they make this choice?
\end{enumerate}

\end{document}